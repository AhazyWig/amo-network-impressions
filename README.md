# AMO network impressios (Test Task)

## Завдання 1
Для реалізації цього завдання я обрав polars, а не pandas
У даному кейсі це кращий варіант, бо:
1. Polars значно швидше за Pandas при групуваннях та агрегаціях великих датасетів (завдяки Rust движку)
2. Polars багатопотоковий, на відміну від Pandas
3. Він краще використовує пам'ять через формат Arrow
Також хорошим варіантом є реалізація через PySpark (особливо для дуже великих датасетів), але для тестового кейсу Polars достатньо

Посилання на реалізацію [Завдання 1](https://github.com/AhazyWig/amo-network-impressions/blob/main/task_1/task_1.ipynb).

## Завдання 2
Для вибору БД проаналізуємо вимоги до бази:
1. Дані надходять щогодини у вигляді файлів з великою кількістю рядків
2. Основна аналітика - BI репорти. Важливо: дохідність по продукту (Product), дохідність по пристрою (DeviceCategory), тренди по сесіях (session_id).
3. Важлива швидка агрегація та фільтрація по часу, продукту, девайсу.
4. Дані late-arriving events (рядки за попередні години можуть приходити пізніше)
5. Очікується інкрементальна обробка файлів без значного оновлення старих даних (в основному додавання).

Загалом, задача є типовою для OLAP системи, тому тут підійде будь-яка OLAP сервіс (GCP, AWS Redshift, Snowflake тощо)
Для цієї задачі можемо обрати BigQuery, тому що це типова швидка OLAP, зручно працювати з великими даними, просте керування партиціюванням, повністю servless рішення, не потрібно займатися ручним тюнінгом при масштабуванні. 
Так як задача є доволі тривіальна, тут підійде будь яка OLAP, стиль і підхід буде у всіх +- однаковий
